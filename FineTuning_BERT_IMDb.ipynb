{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH4VilwYzMcT"
      },
      "outputs": [],
      "source": [
        "# Instalar bibliotecas necessárias\n",
        "!pip install transformers datasets torch scikit-learn\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, pipeline\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamento do dataset IMDb\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Divisão em treinamento, validação e teste\n",
        "train_data = dataset[\"train\"].train_test_split(test_size=0.1)[\"train\"]\n",
        "val_data = dataset[\"train\"].train_test_split(test_size=0.1)[\"test\"]\n",
        "test_data = dataset[\"test\"]"
      ],
      "metadata": {
        "id": "_4gP6KpCzvHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração do tokenizador e modelo\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenização dos textos\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "train_data = train_data.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "val_data = val_data.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "test_data = test_data.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# Preparação dos dados para o Trainer\n",
        "train_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "val_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "# Configuração do modelo\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ],
      "metadata": {
        "id": "JiDFErPn4vu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função personalizada para calcular métricas\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "    }"
      ],
      "metadata": {
        "id": "9nVwbMCJU1-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração do treinamento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",          # Pasta para salvar resultados\n",
        "    evaluation_strategy=\"epoch\",    # Avaliação a cada época\n",
        "    learning_rate=2e-5,             # Taxa de aprendizado\n",
        "    per_device_train_batch_size=16, # Batch size para treino\n",
        "    per_device_eval_batch_size=16,  # Batch size para validação\n",
        "    num_train_epochs=3,             # Número de épocas\n",
        "    weight_decay=0.01,              # Regularização L2 (weight decay)\n",
        "    save_strategy=\"epoch\",          # Salvar modelo a cada época\n",
        "    logging_dir=\"./logs\",           # Diretório para logs\n",
        "    report_to=\"none\",               # Desativa serviços externos (W&B e outros serviços de monitoramento)\n",
        ")\n",
        "\n",
        "# Inicialização do Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,  # Passa as métricas personalizadas\n",
        ")\n",
        "\n",
        "# Fine-Tuning (Treinamento do modelo)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "fUN4T5F3VRvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação final no conjunto de teste\n",
        "results = trainer.evaluate(test_data)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "8SXFBXtY5t1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar o modelo ajustado (Fine-Tuned)\n",
        "model.save_pretrained(\"./fine_tuned_bert\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_bert\")"
      ],
      "metadata": {
        "id": "QstoKuqw54aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inferência com o modelo ajustado e mapeamento de rótulos\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"./fine_tuned_bert\", tokenizer=\"./fine_tuned_bert\")\n",
        "label_map = {\"LABEL_0\": \"NEGATIVE\", \"LABEL_1\": \"POSITIVE\"}\n",
        "\n",
        "# Textos para análise\n",
        "texts = [\n",
        "    \"This movie was fantastic!\",\n",
        "    \"I hated every minute of this film.\",\n",
        "    \"The plot was okay, but the acting was superb.\",\n",
        "    \"I wouldn't recommend this to anyone.\",\n",
        "    \"It was a decent film, not too bad but not great either.\",\n",
        "    \"Absolutely amazing! A masterpiece.\",\n",
        "    \"Terrible, just terrible. A waste of time.\",\n",
        "    \"The visuals were stunning, but the story lacked depth.\",\n",
        "    \"One of the best movies I’ve ever seen!\",\n",
        "    \"It’s not my kind of movie, but it was well-made.\",\n",
        "]\n",
        "\n",
        "# Obtenção e formatação das previsões\n",
        "for text, prediction in zip(texts, sentiment_analyzer(texts)):\n",
        "    label = label_map[prediction[\"label\"]]\n",
        "    score = prediction[\"score\"]\n",
        "    print(f\"text: {text}, label: {label}, score: {score:.4f}\")\n"
      ],
      "metadata": {
        "id": "jEI8IfUDhtE9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}